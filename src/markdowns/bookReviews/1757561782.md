# "Artificial Intelligence: A Guide for Thinking Humans" by Melanie Mitchell

***Completed Reading September 10th 2025***

AI has really come blazing on the public scene since the release of ChatGPT. And for good reasons, of course. LLM like ChatGPT has provided a much more streamlined prompting tool to provide answers (sometimes inaccurate) to most questions within reason. And this boom has initiated an AI arms race where the biggest tech companies are investing billions of dollars into LLM and data centers to find the proverbial holy grail of general artificial intelligence. And i personally think this book does a really good job of providing reasoning around what is possible and not possible with AI.

This isn't the first time AI's potential has been overexaggerated. IBM has made multiple different AI bots (more accurately, brute force search) that were trained in a particular domain. For example, Deep Blue was trained on millions of simulations of chess games to train its neural network to calculate the best moves to make. Combining that with using brute force search to run 200M possible chess moves that could be made, Deep Blue was able to beat the chess master at the time Kasparov.

This pushed IBM's stock up dramatically afterwards and caused a lot of hype around AI's abilities. The,n when the hype of AI started to die down, and it was clear Deep Blue was only phenomenal at chess but nothing else, AI winter came. At the time, the goalpost moved from "AI being able to beat people at games like chess" to "Can AI beat someone in a much more verbose game?"

Then IBM created Watson to compete in the game Jeopardy. Jeopardy is a game that requires not only an understanding of language but also of culture (e.g. Question: The common phrase is used to describe being in a difficult situation. Answer: What is a rock and a hard place?") So the Watson team trained Watson on a multitude of Jeopardy like questions and fined-tuned the weights (via a reward system) based on the answers given back by Watson. With the combination of these new AI methods with the computational improvements since Deep Blue, Watson was able to beat the Jeopardy champion Ken Jennings. Even though Watson won, some of its answers were mystifying because when Watson was wrong, it was wildly wrong. But that didn't stop the hype train from starting again around AI, with IBM stock going up and an overpromise on what AI can accomplish. Then the goalpost moved from "Can AI beat someone in a much more verbose game?" to "Can AI beat someone in a game that requires intuition?"

AlphaGo was created by the DeepMind team at Google. I personally don't know how Go is played, but from what I've read, it's a game that requires a high level of intuition and "thinking outside of the box". Chess and Jeopardy are not games that require much intuition and "subjective" thinking, while Go requires these two skillsets to win. Brute force search for something that has over +10^25 moves would be astronomically impossible to brute force. And just providing training data and reinforcement learning alone would only get AlphaGo so far. So the AlphaGo team introduced the Monte Carlo Tree Search (MCTS). In essence, MCTS would use the previous learning it acquired from its training data and only focus on the most promising moves to render. So instead of going through 10k different moves it could attempt, it would generate only a small set of moves that had the highest probability of AlphaGo winning. This dramatically narrowed the search algorithm needed for Go. With this, AlphaGo was able to beat Lee Sedol, the best Go player at the time. What's really incredible is that Lee Sedol, in an interview, claimed AlphaGo did moves no other Go player has ever done. And the cycle repeats with massive hype around the potential of AI, and Google stocks shoot up after AlphaGo's win over Lee Sedol.

Fast forward to today, and we're currently in another AI boom. LLM models are using convolutional neural networks for image, voice, and text recognition. A massive number of data centers are being built to train these models, so their next version of their neural networks can be even more refined and accurate. So.... the question is: "Are we finally getting to what will be general artificial intelligence, or is this another cycle like all the others mentioned in the book?" Melanie thinks that we're not close to general artificial intelligence in terms of mirroring human-like intelligence. And here's why:

Humans have an attribute called "commonsense knowledge" hardwired into us even as babies. For example, after the age of 3 months, a baby can recognize his or her mother. This comes from the baby's neurons, dendrites, and axons making synapses in the brain to recognize their mother. We humans make more and more neurons and synapse connections as we taste food, touch surfaces, see trees, smell lavender, and hear the voices of our parents. From these five senses, we learn that we shouldn't step on a thumbtack because it will cause us pain. We shouldn't eat a raw cockroach (I know some cultures do eat cockroaches, but bear with me) because the taste will be grotesque. Machines need to be trained on these "commonsense" situations, but there are literally billions upon billions of scenarios a machine would need to be trained on. And even then, that's not intuitive to the machine; that's just the neural networks based on the provided data generating the best possible set of responses.

Maybe one day this will be a reality, but as Melanie said, the only way feasible for an AI machine to truly be "humanlike" is for that machine to inherit the five senses humans use to understand the physical world around us.
